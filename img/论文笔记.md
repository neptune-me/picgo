# 论文笔记

## 1

### 标题

Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

### 主要贡献

以前解决ICS的方法是小学习率、小心地初始化、dropout、用relu这种不会饱和的非线性函数，但现在只需用batch normalization就可以解决ICS，加速训练。

### 方法

<img src="https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211104001856502.png" alt="image-20211104001856502" style="zoom:50%;" />

在激活函数层前面加一层bn层，对输入数据做归一化，这样能让输入激活层的数据落在激活函数的linear regime。

这个归一化公式中的mean和var是根据一个mini-batch计算得来的，而不是全体样本。

### 实验结果

比不加bn的网络准确率更高，收敛更快。输入的分布更稳定。

加了bn与不加bn的网络达到相同的准确率所需要的更新步数是1：2的关系。学习率乘5的话，步数变成1/5。学习率乘30的话，步数比乘5还多点。

### 细节

ICS :Internal Covariate Shift。深度神经网络涉及到很多层的叠加，而**每一层的参数更新**会导致上层的输入数据分布发生变化，通过层层叠加，**高层的输入分布变化会非常剧烈**，这就使得高层需要不断去重新适应底层的参数更新。为了训好模型，我们需要非常谨慎地去设定学习率、初始化权重、以及尽可能细致的参数更新策略。这一现象称为ICS。

饱和：sigmoid函数在变量绝对值很大的时候会出现的现象，意味着函数变得很平，对输入的微小改变不敏感

白化：不知道是啥，固定输入数据的分布，消除ICS副作用

## 2

### 标题

ImageNet Classification with Deep Convolutional Neural Networks

### 主要贡献

训练了一个最大的CNN：5层卷积，3层全连接，在图片分类任务上达到了最高的准确率，训练数据集是ImageNet。实现了GPU上性能很好的2D卷积。网络有一些新的特性，性能好，训练快，可以避免过拟合。

### 方法

![image-20211103152635588](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211103152635588.png)

上半层是GPU0训练的，下半层是GPU1训练的。网络结构是5层卷积，3层全连接。

沿网络传播的过程也是知识压缩的过程：一张人能看懂的图片-》一个机器能识别的向量。

缺点是用大量篇幅描述了多GPU训练的方法（把模型切开），但这个方法不具有通用性。

### 实验结果

![image-20211103160731844](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211103160731844.png)

ILSVRC-2010测试集。

### 细节

过拟合 深度学习的派别，通过正则避免过拟合。现在认为正则不重要，网络的设计更重要。

当时CNN还不是主流，只跟CNN比较不公平

作者把ImageNet的每张图片的分辨率都固定为256*256，具体做法是把短边减小到256，再裁剪。没做其他预处理。**在raw RGB值上训练**（没做其他特征提取，end-to-end，没有手工提取特征）这本来是一个亮点，但作者没有highlight出来。



## 3

### 标题

Deep Residual Learning for Image Recognition

### 主要贡献

残差学习框架来训练非常深的网络，准确率很高。152层深度，计算复杂度还更低

## 5

### 标题

MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

### 主要贡献

提出了一类轻量级的模型，适用于移动端应用

### 方法

![image-20211110101456417](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110101456417.png)

把标准卷积层换成了深度可分离卷积 depthwise separable convolution。分成了两层，一个depthwise卷积层和一个pointwise卷积层。

**标准卷积**

![image-20211110101946212](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110101946212.png)

用三维卷积对三个通道一起卷积。输入一个12×12×3的一个输入特征图，经过5×5×3的卷积核卷积得到一个8×8×1的输出特征图。如果此时我们有256个特征图，我们将会得到一个8×8×256的输出特征图。

**深度卷积**

![image-20211110102108663](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110102108663.png)

depthwise convolution:深度卷积。把卷积核拆分成单通道的形式，分别对每一通道进行卷积，这样就得到了**输出通道数和输入通道数**一致的特征图。输入一个12×12×3的一个输入特征图，经过5×5×1×3的深度卷积得到一个8×8×3的输出特征图。但是这样通道数太少，是否获取到了足够的信息呢？

**逐点卷积**

![image-20211110102618757](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110102618757.png)

pointwise convolution。逐点卷积。其实就是1x1卷积，用于对特征图进行升维或降维。深度卷积得到了8×8×3的特征图，用256个1x1x3的卷积核做逐点卷积，输出一个8×8×256的特征图

**整合**

![image-20211110102941453](https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110102941453.png)



<img src="https://raw.githubusercontent.com/neptune-me/picgo/master/img/image-20211110103639150.png" alt="image-20211110103639150" style="zoom:50%;" />

**网络结构**

28层。标准卷积层-深度可分离卷积层*13-平均池化-全连接

**参数**

width multiplier α:输入通道数和输出通道数都变成原来的α倍。用于获得thiner 模型。

resolution multiplier 

### 实验结果

参数量
