# Squeeze-and-Excitation Networks

## 主要贡献

Squeeze-and-Excitation Networks（SENet）是由自动驾驶公司Momenta在2017年公布的一种全新的图像识别结构。通过建模通道之间的关联，把重要的特征进行强化来提升准确率。这个结构是2017 ILSVR竞赛的冠军，top5的错误率达到了2.251%，比2016年的第一名还要低25%，可谓提升巨大。

## 方法

squeeze-and-excitation block由transformation、squeeze、excitation和scale组成。将特征图做卷积操作，再z做平均池化提取。如图所示：

![这里写图片描述](https://raw.githubusercontent.com/neptune-me/picgo/master/img/2021/11/12/20211112152314.jpeg)

Ftr：将H'xW'xC'的输入特征图映射到HxWxC，输出的每个通道是由输入的所有通道的卷积summation而来。

Fsq: squeeze操作，across spatial dimensions（HxW）整合feature map。其实就是屏蔽空间分布的信息，专心探究通道间的相关性。过程就是global average pooling（GAP），得到1x1xC的输出。

Fex: excitation操作，self-gating机制，为每个通道生成modulation weights矩阵，作用在特征图U上面。过程就是{fc-relu-fc-sigmoid}，第一个全连接把C个通道压缩成了C/r个通道来降低计算量（后面跟了RELU），第二个全连接再恢复回C个通道，（后面跟了Sigmoid，输出在0-1之间）。r是指压缩的比例（r=16时性能和计算量最平衡）。

Fscale: scale操作，把excitation得到的输出s作为scale乘到U的C个通道上， 作为下一级的输入数据。

SENet增加的部分是U后的结构：对U先做一个Global Average Pooling（图中的Fsq(.)，作者称为Squeeze过程），输出的1x1xC数据再经过两级全连接（图中的Fex(.)，作者称为Excitation过程），最后用sigmoid（论文中的self-gating mechanism）限制到[0，1]的范围，把这个值作为scale乘到U的C个通道上， 作为下一级的输入数据。这种结构的原理是想通过控制scale的大小，把重要的特征增强（excites informative features），不重要的特征减弱，从而让提取的特征指向性更强。

**SEblock结构**如图所示，在Inception中的SE block vs 在ResNet中的SE block：

<center class="half">
    <img src="https://raw.githubusercontent.com/neptune-me/picgo/master/img/2021/11/12/20211112210647.jpeg" width="350"/>
    <img src="https://raw.githubusercontent.com/neptune-me/picgo/master/img/2021/11/12/20211112211256.png" width="350"/>
</center>

**SEblock增加的参数数量**：SE-ResNet-50 introduces 2.5 million additional parameters beyond the 25 million parameters required by ResNet-50, corresponding to a 10% increase in the total number of parameters
有一个公式可以计算，就是每个stage多了两个全连接层，全连接层的参数数量。

## 细节

CV的中心主题就是寻找更强力的、能够抓住一个图像最突出的properties的representations。

以前的工作，重点在于提升computational elements的函数形式。比如group convolution、multibranch convolution。作者的工作是建模了通道之间的关联。

为什么excitation操作要加全连接层呢？这是为了利用通道间的相关性来训练出真正的scale。一次mini-batch个样本的squeeze输出并不代表通道真实要调整的scale值，真实的scale要基于全部数据集来训练得出，而不是基于单个batch，所以后面要加个全连接层来进行训练。

